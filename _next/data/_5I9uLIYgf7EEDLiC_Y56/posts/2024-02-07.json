{"pageProps":{"prev":{"meta":{"title":"github blog 구축기(3)","desc":"mdx를 이용한 포스팅 작성","date":"2024.02.06","tags":["next.js","github blog","gh-pages","mdx"]},"content":"\n# 포스팅의 meta정보 입력\n\n- 포스팅의 meta정보를 통해 포스트 리스트 표출시 정보를 표출해야 한다.\n\n![240207-232027](/posts/2024-02-06/240207-232027.png)\n그림1. .mdx 의 meta정보\n\n> getStaticProps로 post가져오기\n\n```typescript\nimport fs from 'fs';\nimport matter from 'gray-matter';\nimport path from 'path';\n\nexport function getPostIds() {\n  const files = fs\n    .readdirSync(path.join('posts'))\n    .filter((filename) => filename.endsWith('.mdx'))\n    .map((filename) => filename.replaceAll('.mdx', ''));\n  return files;\n}\n\nexport function getPostById(postId: string) {\n  const markdownWithMeta = fs.readFileSync(\n    path.join('posts', postId + '.mdx'),\n    'utf-8'\n  );\n  const { data: meta, content } = matter(markdownWithMeta);\n  return {\n    meta: {\n      title: meta['title'] ?? '',\n      desc: meta['desc'] ?? '',\n      date: meta['date'] ?? '',\n      tags: meta['tags'] ?? [],\n    },\n    content,\n    fileName: postId,\n    route: postId,\n  };\n}\n\nexport const getStaticProps: GetStaticProps = async ({ params }) => {\n  const { postId = '' } = params ?? { postId: '' };\n  const postIds = getPostIds();\n  const idx = postIds.findIndex((_postId) => postId === _postId);\n  let prev = null,\n    post = null,\n    next = null;\n  for (let i = 0; i < postIds.length; i++) {\n    const _postId = postIds[i];\n    if (_postId === postId) {\n      prev = i === 0 ? null : getPostById(postIds[i - 1]);\n      post = getPostById(_postId);\n      next = i + 1 === postIds.length ? null : getPostById(postIds[i + 1]);\n      break;\n    }\n  }\n\n  return {\n    props: {\n      prev,\n      post,\n      next,\n    },\n  };\n};\n```\n\nroot folder에 posts 폴더를 만들고 그 내부에 포스트들을 mdx파일로 생성하고, 그 파일들을 읽도록 했다.\n![240208-020424](/posts/2024-02-06/240208-020424.png)\n그림2. folder 구조 및 posts 폴더\n\n이때 폴더명은 포스트가 작성된 날짜를 기준으로 했고, 그 날짜는 mdx 내부에 적어놓은 meta와 동일하게 맞추었다.\n","fileName":"2024-02-06","route":"2024-02-06"},"post":{"meta":{"title":"github blog 구축기(4)","desc":"marked 라이브러리를 통한 markdown csr","date":"2024.02.07","tags":["next.js","github blog","gh-pages","mdx","marked","highlights"]},"content":"\n# mdx로 작성한 파일의 정제\n\n> mdx 작성한 meta 정보를 제거하고싶었다.\n> 하지만 정보 제거에 어려움을 ...ㅠㅠ\n> next.js 내부에서 모두 해결하고자 했으나, 일단 정적 페이지로 만든 페이지의 경우 SEO 적용도 가능하므로\n> 굳이 여기에 시간 쓰지않고, markdown 문법을 react로 표출할 수 있도록 해주는 라이브러리를 찾기로 결정~!\n\n![240208-121859](/posts/2024-02-07/240208-121859.png)\n그림1. markdown 표출에 많이 쓰이는 npm library ( NPM trends )\n\n가장 사용량이 많고, 최근 없데이트가 되는걸로 보이는 marked를 이용하기로 결심\n\n## marked library\n\n> 사용방법이 어렵지 않고, markdown 문법의 문자열을 집어넣어넣고, 그 결과를 innerHTML로 넣으면 간단하게 표출됨을 확인\n\n```tsx\n import { Marked } from 'marked';\n import { markedHighlight } from 'marked-highlight';\n import hljs from 'highlight.js';\n import 'highlight.js/styles/github.css';\n\n const marked = new Marked(\n   markedHighlight({\n     highlight(code, lang) {\n       const language = hljs.getLanguage(lang) ? lang : 'plaintext';\n       return hljs.highlight(code, { language }).value;\n     },\n   })\n );\n\n const renderer = new marked.Renderer();\n\n renderer.code = function (code: string) {\n   return '<div class=\"mockup-code border bg-[#f6f8fa]\" style=\"width:90%;margin:auto;margin-bottom:20px;\"><pre style=\"margin-bottom:0;padding:0;\"><code>\\n${marked.parseInline(code)}</code></pre></div>';\n };\n\n <div\n   className='markdown-body min-h-[58vh] px-6 max-w-[100vw]'\n   dangerouslySetInnerHTML={{\n     __html: marked.parse(post.content, {\n       renderer,\n     }),\n }}>\n```\n\ncode box 영역에 highlight를 적용하고 daisyUI에서 제공하는 mockup-code 를 활용하고 싶어 위와같이 짰다.\n![240208-122304](/posts/2024-02-07/240208-122304.png)\n그림2. daisyUI mockup code UI\n\n이렇게 하면 next.js에서 mdx로 작성한 페이지의 meta정보와 별개로 markdown 문법을 내 입맛에 맞게 표출 할 수 있게 되었다.\n","fileName":"2024-02-07","route":"2024-02-07"},"next":{"meta":{"title":"강화학습에 대한 계층적 이해","desc":"강화학습에 대한 학습","date":"2024.03.19","tags":["AI","machine learning","Reinforce ment learning"]},"content":"\n\n### 1단계: 기본 개념의 이해\n- **에이전트(Agent)**: 강화학습 시스템에서 학습과 행동을 수행하는 주체입니다.\n- **환경(Environment)**: 에이전트가 상호작용하는 외부 세계로, 에이전트의 행동에 반응하여 상태를 변화시키고 보상을 제공합니다.\n- **보상(Reward)**: 에이전트의 행동에 대한 즉각적인 피드백으로, 목표 달성에 얼마나 기여했는지를 나타냅니다.\n- **상태(State)**: 에이전트가 인식할 수 있는 환경의 현재 상황을 나타냅니다.\n\n### 2단계: 행동과 정책의 이해\n- **행동(Action)**: 에이전트가 상태에 따라 취할 수 있는 구체적인 조치입니다.\n- **정책(Policy)**: 주어진 상태에서 어떤 행동을 선택할지 결정하는 규칙 또는 전략입니다.\n\n### 3단계: 가치 함수와 Q-학습\n- **가치 함수(Value Function)**: 특정 정책 하에서 주어진 상태에서 시작하여 기대할 수 있는 미래 보상의 총합을 평가합니다.\n- **Q-함수(Q Function)**: 주어진 상태에서 특정 행동을 취했을 때 기대할 수 있는 미래 보상의 총합을 평가합니다.\n- **Q-러닝(Q-learning)**: 경험을 통해 Q-함수를 학습하는 방법으로, 모델 프리 강화학습 알고리즘 중 하나입니다.\n\n### 4단계: 심화 개념과 전략\n- **에피소드(Episode)**: 초기 상태에서 시작하여 종료 상태에 도달할 때까지의 일련의 행동, 상태, 보상의 시퀀스입니다.\n- **탐험과 활용(Exploration and Exploitation)**: 에이전트가 미지의 행동을 탐험하는 것과 최적의 행동을 활용하는 것 사이의 균형을 맞추는 전략입니다.\n- **감가율(Discount Factor)**: 미래의 보상을 현재 가치로 환산할 때 사용하는 계수로, 먼 미래의 보상을 현재보다 덜 중요하게 평가하는 데 사용됩니다.\n\n### 5단계: 고급 알고리즘과 최적화\n- **정책 그래디언트(Policy Gradient)**: 정책 자체를 직접 최적화하는 기법입니다.\n- **딥 강화학습(Deep Reinforcement Learning)**: 심층 신경망을 이용하여 복잡한 환경에서의 강화학습 문제를 해결하는 방법입니다.\n- **멀티 에이전트 강화학습(Multi-agent Reinforcement Learning)**: 여러 에이전트가 상호작용하는 환경에서의 학습 전략을 다룹니다.\n","fileName":"2024-03-02","route":"2024-03-02"}},"__N_SSG":true}